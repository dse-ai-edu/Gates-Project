{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b06ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from pathlib import Path\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c1d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884b91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745f71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a straightforward teacher who provides clear, balanced feedback without emphasizing any particular teaching philosophy or style.\n",
    "Your response should:\n",
    "- Address the student's work objectively and matter-of-factly\n",
    "- Provide feedback that is neither overly encouraging nor overly critical\n",
    "- Focus on the content and accuracy without emotional framing\n",
    "- Give information and corrections in a neutral, informative manner\n",
    "- Explain concepts clearly and concisely without unnecessary elaboration\n",
    "- Avoid leading questions, excessive praise, or emotional support language\n",
    "- Present information directly without trying to guide discovery or build relationships\n",
    "- Use straightforward language that gets to the point efficiently\n",
    "- Provide necessary corrections and suggestions without pedagogical commentary\n",
    "- Maintain a professional but neutral stance toward the student's learning process\n",
    "\n",
    "Tone: Neutral, informative, professional, matter-of-fact, unadorned.\n",
    "Focus on delivering clear, accurate information and feedback without stylistic embellishment or particular teaching methodology.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "# Task\n",
    "Based on the given question and student answer, please generate a response to the student.\n",
    "\n",
    "# Template of Output Response:\n",
    " - Your feedback response must strictly follow the template below; use ** to decorate the title of subsections (e.g., **title**).\n",
    " - The template is: `Strength; Weakness; Suggestions for Improvement`.\n",
    "\n",
    "# Input Data\n",
    "## Question: {question}. \n",
    "## Student Answer: {answer}.\n",
    "\n",
    "Start your reply immediately with the feedback itself.  \n",
    "Do NOT prepend headings like “Teacher Response”, “## Feedback”, or any introductory sentences.  \n",
    "The first character in your answer must be the first character of the actual feedback response. \n",
    "## Teacher (you) Response [NO MORE THAN *500* WORDS]: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6abc8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"example_answer.json\", \"r\") as f:\n",
    "    example_qa = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_path = './results/GPT-OCR-results-251216.csv'\n",
    "# ocr_df = pd.read_csv(ocr_path)\n",
    "# ocr_df.to_excel('GPT-OCR-results.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d329d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d96dae85",
   "metadata": {},
   "source": [
    "## setting 1 (step 2): feedback from code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0527ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-5-nano\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "        num_tokens += 4\n",
    "    num_tokens += 2\n",
    "    return num_tokens\n",
    "\n",
    "def llm_generate(system_prompt: str, user_prompt: str, model: str = 'gpt-5-nano', max_token: int = 4096) -> str:\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_prompt},\n",
    "        {'role': 'user', 'content': user_prompt}\n",
    "    ]\n",
    "    \n",
    "    existing_num_token = num_tokens_from_messages(messages, model=model)\n",
    "    \n",
    "    while existing_num_token > max_token - 512:\n",
    "        max_token += 512\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        max_completion_tokens=max_token,\n",
    "        messages=messages\n",
    "    )\n",
    "    # 提取文本内容返回\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8897b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_path = './results/GPT-OCR-results-251216A.csv'\n",
    "output_path1 = './results/GPT-setting1-results-251216A.csv'\n",
    "\n",
    "s1_results = pd.read_csv(output_path1, index_col=None)\n",
    "ocr_results = pd.read_csv(ocr_path, index_col=None)\n",
    "\n",
    "\n",
    "# for col in s1_results.columns:\n",
    "#     s1_results[col] = s1_results[col].apply(\n",
    "#         lambda x: \"'\" + x if isinstance(x, str) and x.startswith(\"=\") else x\n",
    "#     )\n",
    "# s1_results = s1_results.sort_values(by=['q_idx', 'a_idx'])\n",
    "# xlsx_path = output_path1.replace('.csv', '.xlsx')\n",
    "# s1_results.to_excel(xlsx_path, index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ff1bfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:00, 14517.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 a2 nan\n",
      "q2 a1 nan\n",
      "q2 a2 nan\n",
      "q2 a3 nan\n",
      "q4 a1 nan\n",
      "q4 a2 nan\n",
      "q5 a3 nan\n",
      "q5 a4 nan\n",
      "q5 a5 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(s1_results.iterrows()):\n",
    "    question, answer = \"q\"+str(row['q_idx']), \"a\"+str(row['a_idx'])\n",
    "    if isinstance(row['feedback'], str) and len(row['feedback'].strip()) > 0:\n",
    "        continue\n",
    "    else:\n",
    "        print(question, answer, row['feedback'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_results = s1_results.drop(columns=['answer']) if \"answer\" in s1_results.columns else s1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s1_results.at[15, 'feedback'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e41c8351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question idx 5 and answer idx 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:30,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Feedback generated for question idx 5 and answer idx 3.\n",
      "Processing question idx 5 and answer idx 4...\n",
      "current feedback is ``````; len=0; next add_up=1\n",
      "current feedback is ``````; len=0; next add_up=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [02:52,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Feedback generated for question idx 5 and answer idx 4.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(s1_results.iterrows()):\n",
    "    question, answer = \"q\"+str(row['q_idx']), \"a\"+str(row['a_idx'])\n",
    "    if isinstance(row['feedback'], str) and len(row['feedback'].strip()) > 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing question idx {row['q_idx']} and answer idx {row['a_idx']}...\")\n",
    "    \n",
    "    # answer_text = row['code']\n",
    "    answer_text = ocr_results.loc[idx, 'answer_code']\n",
    "    question_text = example_qa[question]['content']\n",
    "    user_prompt_this = user_prompt.format(question=question_text, answer=answer_text)\n",
    "    \n",
    "    feedback, add_up = \"\", 0\n",
    "    while str(feedback).strip() == \"\":\n",
    "        print(f\"current feedback is ```{feedback}```; len={len(str(feedback).strip())}; next add_up={add_up}\") if add_up > 0 else None\n",
    "        response = llm_generate(system_prompt, user_prompt_this, max_token = 4096+add_up*512)\n",
    "        add_up += 1\n",
    "        feedback = response.choices[0].message.content if hasattr(response, 'choices') else response\n",
    "    \n",
    "    # print(f\">> {feedback} \\n >> {response} \\n \")\n",
    "    print(f\">> Feedback generated for question idx {row['q_idx']} and answer idx {row['a_idx']}.\")\n",
    "    feedback = \"'\" + feedback if isinstance(feedback, str) and feedback.startswith(\"=\") else feedback\n",
    "    s1_results.at[idx, 'question'] = question_text\n",
    "    # s1_results.at[idx, 'answer'] = answer_text\n",
    "    s1_results.at[idx, 'answer_code'] = answer_text\n",
    "    s1_results.at[idx, 'feedback'] = feedback\n",
    "# \n",
    "    s1_results.to_csv(output_path1, index=False)\n",
    "    xlsx_path1 = output_path1.replace('.csv', '.xlsx')\n",
    "    s1_results.to_excel(xlsx_path1, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [c if c not in ['question','answer_code'] else ('answer_code' if c=='question' else 'question') for c in s1_results.columns.tolist()]\n",
    "# s1_results = s1_results[cols]\n",
    "\n",
    "# s1_results.to_csv(output_path1, index=False)\n",
    "# xlsx_path1 = output_path1.replace('.csv', '.xlsx')\n",
    "# s1_results.to_excel(xlsx_path1, index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = s1_results.drop(columns=['code'])\n",
    "# df1.to_excel(output_path1.replace('csv', 'xlsx'), index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69981d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:23,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "### makeing up mode\n",
    "ocr_results = pd.read_excel('GPT-OCR-results-251209.xlsx', index_col=None)\n",
    "s1_results = pd.read_excel('GPT-setting1-results.xlsx', index_col=None)\n",
    "\n",
    "for idx, row in tqdm(ocr_results.iterrows()):\n",
    "    q_idx, a_idx = row['q_idx'], row['a_idx']\n",
    "#  \n",
    "    if len(s1_results[(s1_results['q_idx'].astype(str) == str(q_idx)) & (s1_results['a_idx'].astype(str) == str(a_idx))]) > 0:\n",
    "        continue\n",
    "#  \n",
    "    question, answer = \"q\"+str(q_idx), \"a\"+str(a_idx)\n",
    "    answer_text = row['code']\n",
    "    question_text = example_qa[question]['content']\n",
    "    user_prompt_this = user_prompt.format(question=question_text, answer=answer_text)\n",
    "    response = llm_generate(system_prompt, user_prompt_this)\n",
    "    feedback = response.choices[0].message.content if hasattr(response, 'choices') else response\n",
    "#  \n",
    "    new_row = {\n",
    "        'q_idx': q_idx,\n",
    "        'a_idx': a_idx,\n",
    "        'question': question_text,\n",
    "        'answer': answer_text,\n",
    "        'feedback': feedback\n",
    "    }\n",
    "    s1_results = pd.concat([s1_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    s1_results = s1_results.sort_values(by=['q_idx', 'a_idx'])\n",
    "    s1_results.to_excel('GPT-setting1-results-251209.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31facf3",
   "metadata": {},
   "source": [
    "## setting 2: feedback directly from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1664c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path: str) -> str:\n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        return base64.standard_b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "def get_image_media_type(image_path: str) -> str:\n",
    "    ext = Path(image_path).suffix.lower()\n",
    "    media_types = {\n",
    "        '.jpg': 'image/jpeg',\n",
    "        '.jpeg': 'image/jpeg',\n",
    "        '.png': 'image/png',\n",
    "        '.gif': 'image/gif',\n",
    "        '.webp': 'image/webp'\n",
    "    }\n",
    "    return media_types.get(ext, 'image/jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3eef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate_cv(\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    image_path: str = None,\n",
    "    model: str = \"gpt-5-nano\"\n",
    ") -> str:\n",
    "\n",
    "    input_content = []\n",
    "\n",
    "    # ---- text input ----\n",
    "    if user_prompt:\n",
    "        input_content.append({\n",
    "            \"type\": \"input_text\",\n",
    "            \"text\": user_prompt\n",
    "        })\n",
    "\n",
    "    # ---- image input ----\n",
    "    if image_path and os.path.exists(image_path):\n",
    "        image_data = encode_image(image_path)\n",
    "        media_type = get_image_media_type(image_path)\n",
    "        input_content.append({\n",
    "            \"type\": \"input_image\",\n",
    "            \"image_url\": f\"data:{media_type};base64,{image_data}\"\n",
    "        })\n",
    "    elif image_path:\n",
    "        print(f\"[ERROR] Image not found: {image_path}\")\n",
    "\n",
    "    # ---- Responses API ----\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": input_content\n",
    "            }\n",
    "        ],\n",
    "        max_output_tokens=8192\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3352bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./Images\"\n",
    "output_path2 = 'GPT-setting2-results-251216b.csv'\n",
    "results = pd.read_csv(output_path2, index_col=None).to_dict(orient='records') if os.path.exists(output_path2) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec906e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20680f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt2 = \"\"\"\n",
    "# Task\n",
    "Based on the given question (shown below) and student answer (shown in the image), please generate a response to the student.\n",
    "\n",
    "# Template of Output Response:\n",
    " - Your feedback response must strictly follow the template below; use ** to decorate the title of subsections (e.g., **title**).\n",
    " - The template is: `Strength; Weakness; Suggestions for Improvement`.\n",
    "\n",
    "# Important:\n",
    " - Start your reply immediately with the feedback itself.  \n",
    " - Do NOT prepend headings like “Teacher Response”, “## Feedback”, or any introductory sentences.  \n",
    " - The first character in your answer must be the first character of the actual feedback response. \n",
    " - If no student answer is provided in the image, please just say \"NO IMAGE PROVIDED\" without any other feedback.\n",
    "\n",
    "# Input Question: {question}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8378f7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 1 a 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:23<09:23, 23.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 1 a 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:46<08:57, 23.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 1 a 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [01:14<09:18, 25.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 1 a 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [01:52<10:40, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 1 a 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [02:19<09:43, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 2 a 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [02:57<10:09, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 2 a 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [03:43<10:58, 36.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 2 a 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [04:45<12:41, 44.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 2 a 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [05:24<11:27, 42.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 2 a 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [06:06<10:39, 42.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 3 a 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [06:33<08:47, 37.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 3 a 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [06:54<07:07, 32.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 3 a 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [07:23<06:20, 31.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 3 a 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [07:56<05:50, 31.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 3 a 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [08:27<05:17, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 4 a 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [09:03<04:57, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 4 a 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [09:48<04:52, 36.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 4 a 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [10:30<04:26, 38.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 4 a 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [11:16<04:03, 40.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 4 a 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [11:57<03:22, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 5 a 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [12:32<02:36, 39.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 5 a 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22/25 [13:06<01:52, 37.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 5 a 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 23/25 [13:34<01:09, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 5 a 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 24/25 [14:14<00:36, 36.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing q 5 a 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [14:49<00:00, 35.59s/it]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(sorted(os.listdir(image_dir))):\n",
    "    if not image_file.lower().endswith('.png'):\n",
    "        continue\n",
    "\n",
    "    q_match = re.findall(r'q(\\d)', image_file)\n",
    "    a_match = re.findall(r'a(\\d)', image_file)\n",
    "\n",
    "    if not q_match or not a_match:\n",
    "        print(f'no q or a idx extracted - {image_file}')\n",
    "        continue\n",
    "\n",
    "    q_idx = str(q_match[0])\n",
    "    a_idx = str(a_match[0])\n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    \n",
    "    if any(str(r['q_idx']) == str(q_idx) and str(r['a_idx']) == str(a_idx) for r in results):\n",
    "        continue\n",
    "    \n",
    "    print(\"processing q {} a {} ...\".format(q_idx, a_idx))\n",
    "    question_text = example_qa[\"q\"+str(q_idx)]['content']\n",
    "    user_prompt_this = user_prompt2.format(question=question_text)\n",
    "    response = llm_generate_cv(system_prompt, user_prompt_this, image_path)\n",
    "    \n",
    "    if hasattr(response, 'choices'):\n",
    "        feedback = response.choices[0].message.content\n",
    "    elif hasattr(response, 'output'):\n",
    "        feedback = response.output[1].content[0].text\n",
    "    else:\n",
    "        feedback = response\n",
    "        \n",
    "    results.append({\n",
    "        'q_idx': q_idx,\n",
    "        'a_idx': a_idx,\n",
    "        'question': question_text,\n",
    "        'answer_path': f\"{image_file}\",\n",
    "        'feedback': str(feedback)\n",
    "    })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.astype(str)\n",
    "    df = df.sort_values(by=['q_idx', 'a_idx'])\n",
    "    df.to_csv(output_path2, index=False)\n",
    "    xlsx_path = output_path2.replace('.csv', '.xlsx')\n",
    "    df.to_excel(xlsx_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "085a9a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_060476285992a7c900694171df725c8190b087f13d1d30bbd3', created_at=1765896671.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-5-nano-2025-08-07', object='response', output=[ResponseReasoningItem(id='rs_060476285992a7c900694171e0572c819094f0343b1ac98314', summary=[], type='reasoning', status=None), ResponseOutputMessage(id='msg_060476285992a7c9006941720460b481909505a1922487d6a0', content=[ResponseOutputText(annotations=[], text='Strength; Weakness; Suggestions for Improvement\\nStrength: No answer is provided to evaluate; cannot assess understanding from the submission.\\nWeakness: The submission contains only a request about the image and does not include any solution steps or final result.\\nSuggestions for Improvement: Provide a complete solution. For the integral ∫ (ln x / x)^2 dx = ∫ (ln x)^2 / x^2 dx, a correct approach is:\\n- Use integration by parts with u = (ln x)^2 and dv = x^-2 dx, so v = -1/x and du = 2(ln x)/x dx.\\n- Then I = ∫ (ln x)^2 / x^2 dx = -(ln x)^2/x + 2∫ (ln x)/x^2 dx.\\n- For J = ∫ (ln x)/x^2 dx, use parts again with u = ln x and dv = x^-2 dx, giving J = -(ln x)/x - 1/x + C.\\n- Combine: I = -(ln x)^2/x + 2[-(ln x)/x - 1/x] + C = -[(ln x)^2 + 2 ln x + 2]/x + C.\\n- Domain note: x > 0.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=8192, previous_response_id=None, reasoning=Reasoning(effort='medium', generate_summary=None, summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), truncation='disabled', usage=ResponseUsage(input_tokens=2589, output_tokens=4561, output_tokens_details=OutputTokensDetails(reasoning_tokens=4288), total_tokens=7150, input_tokens_details={'cached_tokens': 0}), user=None, background=False, billing={'payer': 'developer'}, max_tool_calls=None, prompt_cache_key=None, prompt_cache_retention=None, safety_identifier=None, service_tier='default', store=True, top_logprobs=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063c41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Strength; Weakness; Suggestions for Improvement\\nStrength: No answer is provided to evaluate; cannot assess understanding from the submission.\\nWeakness: The submission contains only a request about the image and does not include any solution steps or final result.\\nSuggestions for Improvement: Provide a complete solution. For the integral ∫ (ln x / x)^2 dx = ∫ (ln x)^2 / x^2 dx, a correct approach is:\\n- Use integration by parts with u = (ln x)^2 and dv = x^-2 dx, so v = -1/x and du = 2(ln x)/x dx.\\n- Then I = ∫ (ln x)^2 / x^2 dx = -(ln x)^2/x + 2∫ (ln x)/x^2 dx.\\n- For J = ∫ (ln x)/x^2 dx, use parts again with u = ln x and dv = x^-2 dx, giving J = -(ln x)/x - 1/x + C.\\n- Combine: I = -(ln x)^2/x + 2[-(ln x)/x - 1/x] + C = -[(ln x)^2 + 2 ln x + 2]/x + C.\\n- Domain note: x > 0.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output[1].content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924f4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "for item in results:\n",
    "    # 将字符串转换回对象\n",
    "    try:\n",
    "        response_obj = ast.literal_eval(item['feedback'])\n",
    "    except Exception:\n",
    "        # 如果不是可解析对象，直接跳过或保持原字符串\n",
    "        response_obj = item['feedback']\n",
    "\n",
    "    # --- 统一提取文本 ---\n",
    "    if hasattr(response_obj, 'choices'):\n",
    "        feedback_text = response_obj.choices[0].message.content\n",
    "    elif hasattr(response_obj, 'output'):\n",
    "        feedback_text = response_obj.output[1].content[0].text\n",
    "    else:\n",
    "        feedback_text = str(response_obj)\n",
    "\n",
    "    # --- 更新 results 中的 feedback ---\n",
    "    item['feedback'] = feedback_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e30de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path3 = output_path2.replace('b.csv', 'c.csv')\n",
    "df = pd.DataFrame(results)\n",
    "df = df.astype(str)\n",
    "df = df.sort_values(by=['q_idx', 'a_idx'])\n",
    "df.to_csv(output_path3, index=False)\n",
    "xlsx_path3 = output_path3.replace('.csv', '.xlsx')\n",
    "df.to_excel(xlsx_path3, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf1f9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(output_path2.replace('csv', 'xlsx'), index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a26200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 2602.38it/s]\n"
     ]
    }
   ],
   "source": [
    "### making up mode\n",
    "\n",
    "image_dir = \"./Images\"\n",
    "output_path2 = 'GPT-setting2-results-251209.xlsx'\n",
    "s2_results = pd.read_excel('GPT-setting2-results.xlsx', index_col=None) \n",
    "\n",
    "for image_file in tqdm(sorted(os.listdir(image_dir))):\n",
    "    if not image_file.lower().endswith('.png'):\n",
    "        continue\n",
    "#  \n",
    "    q_match = re.findall(r'q(\\d)', image_file)\n",
    "    a_match = re.findall(r'a(\\d)', image_file)\n",
    "#  \n",
    "    if not q_match or not a_match:\n",
    "        print(f'no q or a idx extracted - {image_file}')\n",
    "        continue\n",
    "#  \n",
    "    q_idx = str(q_match[0])\n",
    "    a_idx = str(a_match[0])\n",
    "#  \n",
    "    if len(s2_results[(s2_results['q_idx'].astype(str) == q_idx) & (s2_results['a_idx'].astype(str) == a_idx)]) > 0:\n",
    "        continue\n",
    "#  \n",
    "    image_path = os.path.join(image_dir, image_file)\n",
    "    print(\"processing q {} a {} ...\".format(q_idx, a_idx))\n",
    "    question_text = example_qa[\"q\"+str(q_idx)]['content']\n",
    "    user_prompt_this = user_prompt.format(question=question_text, answer=\"`Please refer to the image provided.`\")\n",
    "    response = llm_generate_cv(system_prompt, user_prompt_this, image_path)\n",
    "    feedback = response.choices[0].message.content if hasattr(response, 'choices') else response\n",
    "#  \n",
    "    new_row = {\n",
    "        'q_idx': q_idx,\n",
    "        'a_idx': a_idx,\n",
    "        'question': question_text,\n",
    "        'answer': image_file,\n",
    "        'feedback': str(feedback)\n",
    "    }\n",
    "    s2_results = pd.concat([s2_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    s2_results = s2_results.astype(str).sort_values(by=['q_idx', 'a_idx'])\n",
    "\n",
    "s2_results.to_excel(output_path2, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "website",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
